{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WtqO9g3nj6Y",
        "outputId": "a15d7f0c-cd03-4757-c809-da21ca9ef408"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jun  8 03:40:03 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required Python libraries\n",
        "!pip install ultralytics roboflow pytesseract opencv-python-headless easyocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6dOQGwXn8PO",
        "outputId": "399ee837-0d17-45fc-fb69-3d410745737b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.152-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.66-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from easyocr) (0.25.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from easyocr) (2.1.1)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (2025.6.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.152-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading roboflow-1.1.66-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-bidi, pyclipper, filetype, python-dotenv, pytesseract, pillow-heif, opencv-python-headless, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, idna, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, roboflow, ultralytics-thop, ultralytics, easyocr\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed easyocr-1.7.2 filetype-1.2.0 idna-3.7 ninja-1.11.1.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 pyclipper-1.3.0.post6 pytesseract-0.3.13 python-bidi-0.6.6 python-dotenv-1.1.0 roboflow-1.1.66 ultralytics-8.3.152 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZo2iFl5oUOD",
        "outputId": "63fba19e-b21e-47a0-964f-1bdc14fdd4b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.152 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 41.8/112.6 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import cv2\n",
        "import pytesseract\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from roboflow import Roboflow\n",
        "import easyocr\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# HÃ m hiá»ƒn thá»‹ áº£nh trong Colab\n",
        "def show_image(image, title=\"Image\"):\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "sqFbZrx_qYTa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_datasets():\n",
        "    try:\n",
        "        from roboflow import Roboflow\n",
        "        rf = Roboflow(api_key=\"b1CmorT7gd3GwVuBjzKl\")  # Thay báº±ng khÃ³a API Roboflow cá»§a báº¡n\n",
        "\n",
        "        # Táº£i táº­p dá»¯ liá»‡u Vehicle Registration Plates\n",
        "        project2 = rf.workspace(\"augmented-startups\").project(\"vehicle-registration-plates-trudk\")\n",
        "        dataset2 = project2.version(1).download(\"yolov8\")\n",
        "        print(f\"ÄÃ£ táº£i Vehicle Registration Plates Dataset vÃ o {dataset2.location}\")\n",
        "\n",
        "        # Táº£i táº­p dá»¯ liá»‡u License Plate Number\n",
        "        project3 = rf.workspace(\"project-enduni\").project(\"license-plate-number-uqwhx\")\n",
        "        dataset3 = project3.version(2).download(\"yolov8\")\n",
        "        print(f\"ÄÃ£ táº£i License Plate Number Dataset vÃ o {dataset3.location}\")\n",
        "\n",
        "        return dataset2.location, dataset3.location\n",
        "    except Exception as e:\n",
        "        print(f\"Lá»—i khi táº£i táº­p dá»¯ liá»‡u: {e}\")\n",
        "        return None, None\n",
        "\n",
        "dataset2_path, dataset3_path = download_datasets()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCDajYORoVXE",
        "outputId": "de3d5db7-9f14-42bb-f21e-4460c3a299b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Vehicle-Registration-Plates-1 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 236129/236129 [00:03<00:00, 61974.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Vehicle-Registration-Plates-1 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17658/17658 [00:02<00:00, 8344.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÄÃ£ táº£i Vehicle Registration Plates Dataset vÃ o /content/Vehicle-Registration-Plates-1\n",
            "\rloading Roboflow workspace...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rloading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in License-Plate-Number-2 to yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27390/27390 [00:00<00:00, 36988.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to License-Plate-Number-2 in yolov8:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12400/12400 [00:01<00:00, 11190.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ÄÃ£ táº£i License Plate Number Dataset vÃ o /content/License-Plate-Number-2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_yolo_model(data_path):\n",
        "    try:\n",
        "        from ultralytics import YOLO\n",
        "        model = YOLO(\"yolov8n.pt\")  # Táº£i mÃ´ hÃ¬nh YOLOv8n\n",
        "\n",
        "        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh\n",
        "        results = model.train(\n",
        "            data=f\"{data_path}/data.yaml\",\n",
        "            epochs=20,\n",
        "            imgsz=640,\n",
        "            batch=16,\n",
        "            name='license_plate_detection',\n",
        "            device=0  # Sá»­ dá»¥ng GPU\n",
        "        )\n",
        "        print(\"Huáº¥n luyá»‡n hoÃ n táº¥t!\")\n",
        "        return model, results\n",
        "    except Exception as e:\n",
        "        print(f\"Lá»—i khi huáº¥n luyá»‡n mÃ´ hÃ¬nh: {e}\")\n",
        "        return None, None\n",
        "\n",
        "if dataset2_path:\n",
        "    plate_detection_model, train_results = train_yolo_model(dataset2_path)\n",
        "else:\n",
        "    print(\"KhÃ´ng thá»ƒ huáº¥n luyá»‡n do lá»—i táº£i táº­p dá»¯ liá»‡u\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4RYHBZ-oX8p",
        "outputId": "9da60cd0-8e24-4308-8986-9ea8b2c3774e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 98.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.152 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/Vehicle-Registration-Plates-1/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=license_plate_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/license_plate_detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 22.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:00<00:00, 77.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 752.4Â±577.4 MB/s, size: 27.2 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Vehicle-Registration-Plates-1/train/labels... 6176 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6176/6176 [00:02<00:00, 2346.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Vehicle-Registration-Plates-1/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 467.9Â±241.6 MB/s, size: 16.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Vehicle-Registration-Plates-1/valid/labels... 1765 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1765/1765 [00:01<00:00, 1274.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Vehicle-Registration-Plates-1/valid/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/license_plate_detection/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/license_plate_detection\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/20      2.02G      1.239      1.414      1.118         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:45<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:13<00:00,  4.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.962      0.908      0.946      0.623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/20      2.68G      1.229     0.7917      1.107         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:40<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:12<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.955      0.913      0.944      0.591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/20      2.68G      1.223     0.7087      1.105         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:39<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.968      0.899      0.948      0.636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/20       2.7G      1.203     0.6662       1.09         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:42<00:00,  3.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.952      0.922      0.954      0.615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/20      2.71G      1.187      0.632      1.089         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:40<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.968      0.929      0.958      0.658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/20      2.73G      1.176     0.6089      1.081         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:39<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.981      0.937      0.973      0.683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/20      2.75G      1.158     0.5779      1.075         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:38<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.969      0.943      0.971      0.675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/20      2.77G      1.152     0.5595      1.065         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:40<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.978      0.946      0.973      0.679\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/20      2.78G      1.127     0.5494      1.057         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:40<00:00,  3.85it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.984      0.947      0.974       0.68\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/20       2.8G       1.13     0.5366      1.055         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:44<00:00,  3.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:12<00:00,  4.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.967      0.949      0.975      0.677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/20      2.82G      1.107     0.4952      1.072         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:42<00:00,  3.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.981      0.935      0.977      0.697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/20      2.83G      1.097     0.4898      1.065         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:36<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.981      0.954      0.979      0.694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/20      2.85G      1.088     0.4729      1.063         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:35<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:12<00:00,  4.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.981      0.954      0.982      0.703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/20      2.87G      1.072     0.4656      1.052         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:36<00:00,  3.99it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.985      0.946      0.981      0.701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/20      2.88G      1.067      0.447      1.052         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:36<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.983      0.952       0.98      0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/20       2.9G      1.055     0.4347      1.041         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:35<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.983      0.961      0.984      0.707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/20      2.92G      1.049     0.4246      1.041         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:35<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.989       0.95      0.985      0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/20      2.94G       1.04     0.4159      1.036         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:35<00:00,  4.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.981      0.955      0.982      0.706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/20      2.95G      1.028     0.4039      1.029         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:34<00:00,  4.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.982      0.958      0.986       0.72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/20      2.97G      1.014     0.3911      1.021         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 386/386 [01:35<00:00,  4.03it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:11<00:00,  4.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.987      0.953      0.986      0.719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "20 epochs completed in 0.617 hours.\n",
            "Optimizer stripped from runs/detect/license_plate_detection/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/license_plate_detection/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/license_plate_detection/weights/best.pt...\n",
            "Ultralytics 8.3.152 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:13<00:00,  4.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.982      0.958      0.986       0.72\n",
            "Speed: 0.2ms preprocess, 1.6ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/license_plate_detection\u001b[0m\n",
            "Huáº¥n luyá»‡n hoÃ n táº¥t!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh phÃ¡t hiá»‡n biá»ƒn sá»‘\n",
        "def evaluate_model(model, data_path):\n",
        "    try:\n",
        "        # ÄÃ¡nh giÃ¡ trÃªn táº­p validation\n",
        "        val_results = model.val(data=f\"{data_path}/data.yaml\", split=\"val\")\n",
        "        print(\"Káº¿t quáº£ validation:\")\n",
        "        print(f\"mAP50: {val_results.box.map50:.3f}, mAP50-95: {val_results.box.map:.3f}\")\n",
        "\n",
        "        # ÄÃ¡nh giÃ¡ trÃªn táº­p test\n",
        "        test_results = model.val(data=f\"{data_path}/data.yaml\", split=\"test\")\n",
        "        print(\"Káº¿t quáº£ test:\")\n",
        "        print(f\"mAP50: {test_results.box.map50:.3f}, mAP50-95: {test_results.box.map:.3f}\")\n",
        "\n",
        "        return val_results, test_results\n",
        "    except Exception as e:\n",
        "        print(f\"Lá»—i khi Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Cháº¡y Ä‘Ã¡nh giÃ¡\n",
        "if plate_detection_model:\n",
        "    val_results, test_results = evaluate_model(plate_detection_model, dataset2_path)\n",
        "else:\n",
        "    print(\"KhÃ´ng thá»ƒ Ä‘Ã¡nh giÃ¡ do lá»—i huáº¥n luyá»‡n mÃ´ hÃ¬nh\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trupzwevsvxz",
        "outputId": "52bcbeb2-ef0c-409c-a564-78ad050c482d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.152 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,005,843 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1244.5Â±1014.4 MB/s, size: 44.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Vehicle-Registration-Plates-1/valid/labels.cache... 1765 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1765/1765 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 111/111 [00:14<00:00,  7.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all       1765       1840      0.983      0.958      0.986      0.719\n",
            "Speed: 0.3ms preprocess, 2.7ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/license_plate_detection2\u001b[0m\n",
            "Káº¿t quáº£ validation:\n",
            "mAP50: 0.986, mAP50-95: 0.719\n",
            "Ultralytics 8.3.152 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 784.1Â±231.6 MB/s, size: 20.4 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Vehicle-Registration-Plates-1/test/labels... 882 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 882/882 [00:00<00:00, 2496.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Vehicle-Registration-Plates-1/test/labels.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:07<00:00,  7.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        882        902      0.993      0.969      0.992      0.727\n",
            "Speed: 0.3ms preprocess, 2.7ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/license_plate_detection3\u001b[0m\n",
            "Káº¿t quáº£ test:\n",
            "mAP50: 0.992, mAP50-95: 0.727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Huáº¥n luyá»‡n mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± vá»›i YOLOv8n\n",
        "def train_character_recognition_model(data_path):\n",
        "    try:\n",
        "        model = YOLO(\"yolov8n.pt\")  # Táº£i mÃ´ hÃ¬nh YOLOv8n má»›i\n",
        "\n",
        "        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh cho nháº­n dáº¡ng kÃ½ tá»±\n",
        "        results = model.train(\n",
        "            data=f\"{data_path}/data.yaml\",\n",
        "            epochs=50,  # TÄƒng epochs cho nháº­n dáº¡ng kÃ½ tá»±\n",
        "            imgsz=640,\n",
        "            batch=16,\n",
        "            name='character_recognition',\n",
        "            device=0  # Sá»­ dá»¥ng GPU\n",
        "        )\n",
        "        print(\"Huáº¥n luyá»‡n mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± hoÃ n táº¥t!\")\n",
        "        return model, results\n",
        "    except Exception as e:\n",
        "        print(f\"Lá»—i khi huáº¥n luyá»‡n mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»±: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Cháº¡y huáº¥n luyá»‡n cho nháº­n dáº¡ng kÃ½ tá»±\n",
        "if dataset3_path:\n",
        "    character_model, char_train_results = train_character_recognition_model(dataset3_path)\n",
        "else:\n",
        "    print(\"KhÃ´ng thá»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± do lá»—i táº£i dataset\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ5bbipVsyVU",
        "outputId": "6e04e957-1d8d-4625-9a2d-0056621059e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.152 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/License-Plate-Number-2/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=character_recognition, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/character_recognition, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=30\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    757162  ultralytics.nn.modules.head.Detect           [30, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,016,698 parameters, 3,016,682 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 177.0Â±61.1 MB/s, size: 3.5 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/License-Plate-Number-2/train/labels... 4750 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4750/4750 [00:01<00:00, 2377.66it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/License-Plate-Number-2/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.2Â±0.5 ms, read: 86.1Â±42.5 MB/s, size: 3.4 KB)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/License-Plate-Number-2/valid/labels... 707 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 707/707 [00:00<00:00, 928.69it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/License-Plate-Number-2/valid/labels.cache\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to runs/detect/character_recognition/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000294, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/character_recognition\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50      2.38G      1.291      3.089      1.272        220        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:20<00:00,  3.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.33it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.826      0.348      0.398       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/50      2.54G      1.126      1.349      1.182        201        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.74it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736       0.66      0.679      0.738       0.53\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/50      2.54G       1.09      1.037      1.151        201        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:14<00:00,  3.97it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.76it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736       0.86      0.864      0.916      0.657\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/50      2.54G      1.075     0.9254      1.138        156        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:07<00:00,  3.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.915      0.897      0.949      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/50      2.54G      1.061     0.8698      1.132        177        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:21<00:00,  3.67it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.21it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.926      0.926      0.963      0.696\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/50      2.54G      1.046     0.8138      1.124        228        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.45it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736       0.93      0.937      0.959      0.695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/50      2.54G      1.039     0.7825       1.12        229        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.05it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.946       0.93      0.966      0.704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/50      2.54G      1.037      0.753      1.121        197        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.32it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.952      0.926      0.972      0.707\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/50      2.54G      1.031     0.7325      1.118        170        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.63it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.946      0.951      0.969      0.714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/50      2.54G      1.029     0.7117      1.116        212        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.16it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.956      0.944      0.973      0.716\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/50      2.54G       1.02     0.6926       1.11        233        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.31it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.953      0.946      0.974      0.714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/50      2.55G      1.017     0.6705      1.111        161        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.70it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.963      0.941      0.975      0.719\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/50      2.56G      1.019     0.6668      1.114        156        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.29it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.955      0.952      0.971      0.703\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/50      2.58G      1.014     0.6529      1.112        155        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.962      0.955      0.977      0.718\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/50       2.6G      1.012     0.6506      1.113        249        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.71it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.967      0.947      0.976       0.72\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/50      2.62G      1.003     0.6224      1.105        194        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.23it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.963      0.955      0.972      0.718\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/50      2.63G      1.005      0.622       1.11        172        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.49it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.971      0.952      0.975      0.725\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/50      2.65G      1.003     0.6123      1.109        204        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.29it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736       0.96      0.959      0.976      0.719\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/50      2.67G     0.9937     0.6017      1.107        196        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.92it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.956      0.964      0.977      0.725\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/50      2.68G     0.9942     0.5938      1.106        219        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.67it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.961      0.965      0.978      0.728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/50       2.7G     0.9886      0.589      1.105        231        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.23it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.969      0.955      0.979      0.728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/50      2.72G     0.9885     0.5857      1.103        155        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:18<00:00,  3.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.99it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.966      0.951      0.978      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/50      2.73G     0.9844      0.576      1.097        228        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.85it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.969      0.952      0.979      0.726\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/50      2.75G     0.9858     0.5774      1.104        184        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.37it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.957      0.942      0.977      0.732\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/50      2.77G     0.9758     0.5666      1.101        165        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.76it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.969      0.954       0.98      0.729\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/50      2.79G     0.9758     0.5653        1.1        239        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.84it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.39it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.967      0.957       0.98      0.728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/50       2.8G     0.9762     0.5604        1.1        170        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:17<00:00,  3.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.77it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.967      0.949      0.979      0.732\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      28/50      2.82G     0.9735     0.5534      1.098        209        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:15<00:00,  3.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.93it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.966       0.95       0.98      0.733\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      29/50      2.84G     0.9684     0.5501        1.1        174        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:15<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.43it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.965      0.961      0.977      0.729\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      30/50      2.85G     0.9665     0.5459      1.092        172        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.78it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736       0.96       0.96      0.978      0.728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      31/50      2.87G     0.9649     0.5426      1.095        192        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.33it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.974      0.957      0.977      0.731\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      32/50      2.89G     0.9602     0.5353      1.093        195        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.77it/s]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all        707       5736      0.974      0.955      0.979      0.735\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      33/50       2.9G      0.965     0.5395      1.098        185        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:15<00:00,  3.91it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.969      0.959      0.979      0.739\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      34/50      2.92G     0.9576     0.5335      1.093        154        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736       0.97      0.957       0.98      0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      35/50      2.94G     0.9534     0.5311       1.09        197        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.968      0.956      0.978      0.731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      36/50      2.96G     0.9522     0.5218      1.091        180        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736       0.97      0.953      0.981      0.738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      37/50      2.97G     0.9509     0.5196      1.088        161        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.86it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.973      0.958       0.98      0.733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      38/50      2.99G     0.9431     0.5163      1.079        191        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.973      0.958      0.981      0.731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      39/50      3.01G     0.9427     0.5144      1.084        163        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:15<00:00,  3.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.968      0.959      0.978      0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      40/50      3.03G     0.9414     0.5129      1.084        200        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:16<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.971      0.962       0.98      0.734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      41/50      3.04G     0.9012     0.3932      1.127        114        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:13<00:00,  4.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.961      0.962      0.978      0.729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      42/50      3.06G      0.895     0.3843      1.126        112        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:11<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.971       0.95      0.976      0.731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      43/50      3.08G     0.8902     0.3801      1.124        112        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:11<00:00,  4.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:05<00:00,  4.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.966      0.965      0.977      0.729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      44/50      3.09G     0.8839     0.3752      1.119        114        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:10<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736       0.97      0.961      0.977      0.731\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      45/50      3.11G     0.8835     0.3744      1.118        107        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 297/297 [01:10<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23/23 [00:06<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all        707       5736      0.968      0.959      0.976      0.732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      46/50      3.13G     0.8765     0.3714       1.11        123        640:  27%|â–ˆâ–ˆâ–‹       | 80/297 [00:18<00:50,  4.28it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Huáº¥n luyá»‡n mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± vá»›i YOLOv8s\n",
        "def train_character_recognition_model_v8s(data_path):\n",
        "    try:\n",
        "        model = YOLO(\"yolov8s.pt\")  # Táº£i mÃ´ hÃ¬nh YOLOv8s (lá»›n hÆ¡n v8n)\n",
        "\n",
        "        # Huáº¥n luyá»‡n mÃ´ hÃ¬nh YOLOv8s cho nháº­n dáº¡ng kÃ½ tá»±\n",
        "        results = model.train(\n",
        "            data=f\"{data_path}/data.yaml\",\n",
        "            epochs=50,  # TÄƒng epochs cho nháº­n dáº¡ng kÃ½ tá»±\n",
        "            imgsz=640,\n",
        "            batch=16,\n",
        "            name='character_recognition_v8s',  # TÃªn khÃ¡c Ä‘á»ƒ phÃ¢n biá»‡t\n",
        "            device=0  # Sá»­ dá»¥ng GPU\n",
        "        )\n",
        "\n",
        "        print(\"Huáº¥n luyá»‡n mÃ´ hÃ¬nh YOLOv8s nháº­n dáº¡ng kÃ½ tá»± hoÃ n táº¥t!\")\n",
        "        return model, results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Lá»—i khi huáº¥n luyá»‡n mÃ´ hÃ¬nh YOLOv8s nháº­n dáº¡ng kÃ½ tá»±: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Cháº¡y huáº¥n luyá»‡n cho nháº­n dáº¡ng kÃ½ tá»± vá»›i YOLOv8s\n",
        "if dataset3_path:\n",
        "    character_model_v8s, char_train_results_v8s = train_character_recognition_model_v8s(dataset3_path)\n",
        "else:\n",
        "    print(\"KhÃ´ng thá»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh YOLOv8s nháº­n dáº¡ng kÃ½ tá»± do lá»—i táº£i dataset\")"
      ],
      "metadata": {
        "id": "RZ7ZBbihs2j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± (YOLOv8n)\n",
        "if character_model:\n",
        "    print(\"ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»±:\")\n",
        "    char_val_results, char_test_results = evaluate_model(character_model, dataset3_path)\n",
        "else:\n",
        "    print(\"KhÃ´ng thá»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»±\")\n",
        "\n",
        "# ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± (YOLOv8s)\n",
        "if character_model_v8s:\n",
        "    print(\"ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh YOLOv8s nháº­n dáº¡ng kÃ½ tá»±:\")\n",
        "    char_val_results_v8s, char_test_results_v8s = evaluate_model(character_model_v8s, dataset3_path)\n",
        "else:\n",
        "    print(\"KhÃ´ng thá»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh YOLOv8s nháº­n dáº¡ng kÃ½ tá»±\")"
      ],
      "metadata": {
        "id": "4VN1Nvl4s33f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models_performance():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"SO SÃNH Káº¾T QUáº¢ GIá»®A YOLOv8n VÃ€ YOLOv8s\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if character_model and character_model_v8s:\n",
        "        print(\"\\n--- YOLOv8n Character Recognition ---\")\n",
        "        if char_val_results:\n",
        "            try:\n",
        "                # Truy cáº­p thuá»™c tÃ­nh box.map50 vÃ  box.map\n",
        "                map50 = getattr(char_val_results.box, 'map50', 'N/A')\n",
        "                map = getattr(char_val_results.box, 'map', 'N/A')\n",
        "                print(f\"Validation mAP50: {map50}\")\n",
        "                print(f\"Validation mAP50-95: {map}\")\n",
        "            except:\n",
        "                print(\"KhÃ´ng thá»ƒ truy cáº­p metrics cá»§a YOLOv8n\")\n",
        "\n",
        "        if char_test_results:\n",
        "            try:\n",
        "                map50 = getattr(char_test_results.box, 'map50', 'N/A')\n",
        "                map = getattr(char_test_results.box, 'map', 'N/A')\n",
        "                print(f\"Test mAP50: {map50}\")\n",
        "                print(f\"Test mAP50-95: {map}\")\n",
        "            except:\n",
        "                print(\"KhÃ´ng thá»ƒ truy cáº­p test metrics cá»§a YOLOv8n\")\n",
        "\n",
        "        print(\"\\n--- YOLOv8s Character Recognition ---\")\n",
        "        if char_val_results_v8s:\n",
        "            try:\n",
        "                map50 = getattr(char_val_results_v8s.box, 'map50', 'N/A')\n",
        "                map = getattr(char_val_results_v8s.box, 'map', 'N/A')\n",
        "                print(f\"Validation mAP50: {map50}\")\n",
        "                print(f\"Validation mAP50-95: {map}\")\n",
        "            except:\n",
        "                print(\"KhÃ´ng thá»ƒ truy cáº­p metrics cá»§a YOLOv8s\")\n",
        "\n",
        "        if char_test_results_v8s:\n",
        "            try:\n",
        "                map50 = getattr(char_test_results_v8s.box, 'map50', 'N/A')\n",
        "                map = getattr(char_test_results_v8s.box, 'map', 'N/A')\n",
        "                print(f\"Test mAP50: {map50}\")\n",
        "                print(f\"Test mAP50-95: {map}\")\n",
        "            except:\n",
        "                print(\"KhÃ´ng thá»ƒ truy cáº­p test metrics cá»§a YOLOv8s\")\n",
        "\n",
        "        print(\"\\n--- Káº¿t luáº­n ---\")\n",
        "        print(\"YOLOv8s thÆ°á»ng cÃ³ Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n YOLOv8n nhÆ°ng cháº­m hÆ¡n vÃ  náº·ng hÆ¡n\")\n",
        "        print(\"YOLOv8n nhanh hÆ¡n vÃ  nháº¹ hÆ¡n, phÃ¹ há»£p cho inference real-time\")\n",
        "\n",
        "    else:\n",
        "        print(\"KhÃ´ng thá»ƒ so sÃ¡nh do má»™t trong hai mÃ´ hÃ¬nh chÆ°a Ä‘Æ°á»£c train thÃ nh cÃ´ng\")\n",
        "\n",
        "# Cháº¡y so sÃ¡nh\n",
        "compare_models_performance()"
      ],
      "metadata": {
        "id": "aCRGiOHHtBvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_license_plate_text(image_path, plate_model, char_model):\n",
        "    \"\"\"\n",
        "    HÃ m tá»•ng há»£p Ä‘á»ƒ phÃ¡t hiá»‡n biá»ƒn sá»‘ vÃ  nháº­n dáº¡ng kÃ½ tá»± chá»‰ báº±ng YOLO\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Äá»c áº£nh\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(f\"KhÃ´ng thá»ƒ Ä‘á»c áº£nh: {image_path}\")\n",
        "            return None\n",
        "\n",
        "        # BÆ°á»›c 1: PhÃ¡t hiá»‡n biá»ƒn sá»‘\n",
        "        plate_results = plate_model(image)\n",
        "\n",
        "        extracted_texts = []\n",
        "\n",
        "        for result in plate_results:\n",
        "            boxes = result.boxes\n",
        "            if boxes is not None:\n",
        "                for box in boxes:\n",
        "                    # Láº¥y tá»a Ä‘á»™ bounding box\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "\n",
        "                    # Cáº¯t vÃ¹ng biá»ƒn sá»‘\n",
        "                    license_plate = image[y1:y2, x1:x2]\n",
        "\n",
        "                    if license_plate.size > 0:\n",
        "                        # Sá»­ dá»¥ng mÃ´ hÃ¬nh YOLO nháº­n dáº¡ng kÃ½ tá»±\n",
        "                        char_results = char_model(license_plate)\n",
        "                        yolo_text = \"\"\n",
        "\n",
        "                        # Sáº¯p xáº¿p cÃ¡c kÃ½ tá»± theo vá»‹ trÃ­\n",
        "                        char_detections = []\n",
        "                        for char_result in char_results:\n",
        "                            if char_result.boxes is not None:\n",
        "                                for char_box in char_result.boxes:\n",
        "                                    x_char = float(char_box.xyxy[0][0])  # Tá»a Ä‘á»™ x cá»§a kÃ½ tá»±\n",
        "                                    class_id = int(char_box.cls[0])\n",
        "                                    confidence = float(char_box.conf[0])\n",
        "\n",
        "                                    # Láº¥y tÃªn class tá»« model\n",
        "                                    if hasattr(char_result, 'names') and class_id in char_result.names:\n",
        "                                        char = char_result.names[class_id]\n",
        "                                        char_detections.append((x_char, char, confidence))\n",
        "\n",
        "                        # Sáº¯p xáº¿p theo tá»a Ä‘á»™ x (tá»« trÃ¡i sang pháº£i) vÃ  ghÃ©p thÃ nh chuá»—i\n",
        "                        char_detections.sort(key=lambda x: x[0])\n",
        "                        yolo_text = ''.join([char for _, char, _ in char_detections])\n",
        "\n",
        "                        # TÃ­nh confidence trung bÃ¬nh\n",
        "                        avg_confidence = sum([conf for _, _, conf in char_detections]) / len(char_detections) if char_detections else 0.0\n",
        "\n",
        "                        # Káº¿t quáº£\n",
        "                        result_dict = {\n",
        "                            'bbox': (x1, y1, x2, y2),\n",
        "                            'text': yolo_text,\n",
        "                            'confidence': avg_confidence,\n",
        "                            'char_details': char_detections,\n",
        "                            'license_plate_image': license_plate\n",
        "                        }\n",
        "\n",
        "                        extracted_texts.append(result_dict)\n",
        "\n",
        "        return extracted_texts\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "rYkVi3CstIZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_yolo_ocr_system():\n",
        "    \"\"\"\n",
        "    Test há»‡ thá»‘ng OCR vá»›i cáº£ hai mÃ´ hÃ¬nh YOLOv8n vÃ  YOLOv8s\n",
        "    \"\"\"\n",
        "    if not plate_detection_model:\n",
        "        print(\"Cáº§n cÃ³ mÃ´ hÃ¬nh phÃ¡t hiá»‡n biá»ƒn sá»‘ Ä‘á»ƒ test!\")\n",
        "        return\n",
        "\n",
        "    # Kiá»ƒm tra mÃ´ hÃ¬nh nÃ o cÃ³ sáºµn\n",
        "    models_to_test = []\n",
        "    if character_model:\n",
        "        models_to_test.append((\"YOLOv8n\", character_model))\n",
        "    if character_model_v8s:\n",
        "        models_to_test.append((\"YOLOv8s\", character_model_v8s))\n",
        "\n",
        "    if not models_to_test:\n",
        "        print(\"Cáº§n cÃ³ Ã­t nháº¥t má»™t mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± Ä‘á»ƒ test!\")\n",
        "        return\n",
        "\n",
        "    # Láº¥y má»™t sá»‘ áº£nh test tá»« dataset\n",
        "    test_images_path = f\"{dataset2_path}/test/images\"\n",
        "\n",
        "    if os.path.exists(test_images_path):\n",
        "        test_images = os.listdir(test_images_path)[:5]  # Test 5 áº£nh Ä‘áº§u tiÃªn\n",
        "\n",
        "        for img_name in test_images:\n",
        "            img_path = os.path.join(test_images_path, img_name)\n",
        "            print(f\"\\n{'='*60}\")\n",
        "            print(f\"Xá»­ lÃ½ áº£nh: {img_name}\")\n",
        "            print('='*60)\n",
        "\n",
        "            # Test vá»›i tá»«ng mÃ´ hÃ¬nh\n",
        "            for model_name, char_model in models_to_test:\n",
        "                print(f\"\\n--- Káº¿t quáº£ vá»›i {model_name} ---\")\n",
        "                results = extract_license_plate_text(img_path, plate_detection_model, char_model)\n",
        "\n",
        "                if results:\n",
        "                    for i, result in enumerate(results):\n",
        "                        print(f\"  Biá»ƒn sá»‘ {i+1}:\")\n",
        "                        print(f\"    Text: {result['text']}\")\n",
        "                        print(f\"    Confidence: {result['confidence']:.3f}\")\n",
        "                        print(f\"    Chi tiáº¿t kÃ½ tá»±: {result['char_details']}\")\n",
        "\n",
        "                        # Hiá»ƒn thá»‹ áº£nh biá»ƒn sá»‘ Ä‘Ã£ cáº¯t (chá»‰ láº§n Ä‘áº§u tiÃªn)\n",
        "                        if model_name == models_to_test[0][0]:\n",
        "                            show_image(result['license_plate_image'], f\"License Plate {i+1} from {img_name}\")\n",
        "                else:\n",
        "                    print(\"    KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c biá»ƒn sá»‘\")\n",
        "    else:\n",
        "        print(f\"KhÃ´ng tÃ¬m tháº¥y thÆ° má»¥c test: {test_images_path}\")\n",
        "\n",
        "# Cháº¡y test\n",
        "test_yolo_ocr_system()"
      ],
      "metadata": {
        "id": "xBk0L0kKtM4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_models():\n",
        "    \"\"\"\n",
        "    LÆ°u táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Táº¡o thÆ° má»¥c lÆ°u mÃ´ hÃ¬nh\n",
        "        os.makedirs('/content/saved_models', exist_ok=True)\n",
        "\n",
        "        # Láº¥y thÆ° má»¥c lÃ m viá»‡c hiá»‡n táº¡i\n",
        "        current_dir = os.getcwd()\n",
        "        print(f\"ThÆ° má»¥c lÃ m viá»‡c hiá»‡n táº¡i: {current_dir}\")\n",
        "\n",
        "        if plate_detection_model:\n",
        "            # LÆ°u mÃ´ hÃ¬nh phÃ¡t hiá»‡n biá»ƒn sá»‘\n",
        "            plate_detection_model.save('/content/saved_models/plate_detection_model.pt')\n",
        "            print(\"ÄÃ£ lÆ°u mÃ´ hÃ¬nh phÃ¡t hiá»‡n biá»ƒn sá»‘\")\n",
        "\n",
        "        if character_model:\n",
        "            # LÆ°u mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± YOLOv8n\n",
        "            character_model.save('/content/saved_models/character_recognition_yolov8n.pt')\n",
        "            print(\"ÄÃ£ lÆ°u mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± YOLOv8n\")\n",
        "\n",
        "        if character_model_v8s:\n",
        "            # LÆ°u mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± YOLOv8s\n",
        "            character_model_v8s.save('/content/saved_models/character_recognition_yolov8s.pt')\n",
        "            print(\"ÄÃ£ lÆ°u mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»± YOLOv8s\")\n",
        "\n",
        "        # Copy best weights\n",
        "        import shutil\n",
        "\n",
        "        # Plate detection best weights\n",
        "        plate_best_path = '/content/runs/detect/license_plate_detection/weights/best.pt'\n",
        "        if os.path.exists(plate_best_path):\n",
        "            shutil.copy(plate_best_path, '/content/saved_models/plate_detection_best.pt')\n",
        "            print(\"ÄÃ£ copy best weights cho phÃ¡t hiá»‡n biá»ƒn sá»‘\")\n",
        "        else:\n",
        "            print(f\"KhÃ´ng tÃ¬m tháº¥y file: {plate_best_path}\")\n",
        "\n",
        "        # Character recognition YOLOv8n best weights\n",
        "        char_v8n_best_path = '/content/runs/detect/character_recognition/weights/best.pt'\n",
        "        if os.path.exists(char_v8n_best_path):\n",
        "            shutil.copy(char_v8n_best_path, '/content/saved_models/character_recognition_yolov8n_best.pt')\n",
        "            print(\"ÄÃ£ copy best weights cho nháº­n dáº¡ng kÃ½ tá»± YOLOv8n\")\n",
        "        else:\n",
        "            print(f\"KhÃ´ng tÃ¬m tháº¥y file: {char_v8n_best_path}\")\n",
        "\n",
        "        # Character recognition YOLOv8s best weights\n",
        "        char_v8s_best_path = '/content/runs/detect/character_recognition_v8s/weights/best.pt'\n",
        "        if os.path.exists(char_v8s_best_path):\n",
        "            shutil.copy(char_v8s_best_path, '/content/saved_models/character_recognition_yolov8s_best.pt')\n",
        "            print(\"ÄÃ£ copy best weights cho nháº­n dáº¡ng kÃ½ tá»± YOLOv8s\")\n",
        "        else:\n",
        "            print(f\"KhÃ´ng tÃ¬m tháº¥y file: {char_v8s_best_path}\")\n",
        "\n",
        "        print(\"\\nCÃ¡c file mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: /content/saved_models/\")\n",
        "        print(\"Danh sÃ¡ch file:\")\n",
        "\n",
        "        # Liá»‡t kÃª cÃ¡c file Ä‘Ã£ lÆ°u\n",
        "        saved_files = os.listdir('/content/saved_models/')\n",
        "        for file in saved_files:\n",
        "            file_path = os.path.join('/content/saved_models/', file)\n",
        "            file_size = os.path.getsize(file_path)\n",
        "            print(f\"  - {file} ({file_size/1024/1024:.2f} MB)\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Lá»—i khi lÆ°u mÃ´ hÃ¬nh: {e}\")\n",
        "\n",
        "        # Debug: Kiá»ƒm tra cÃ¡c Ä‘Æ°á»ng dáº«n\n",
        "        paths_to_check = [\n",
        "            '/content/runs/detect/license_plate_detection/weights/best.pt',\n",
        "            '/content/runs/detect/character_recognition/weights/best.pt',\n",
        "            '/content/runs/detect/character_recognition_v8s/weights/best.pt'\n",
        "        ]\n",
        "\n",
        "        print(\"\\nKiá»ƒm tra cÃ¡c Ä‘Æ°á»ng dáº«n:\")\n",
        "        for path in paths_to_check:\n",
        "            exists = os.path.exists(path)\n",
        "            print(f\"  {path}: {'âœ“' if exists else 'âœ—'}\")\n",
        "\n",
        "# LÆ°u mÃ´ hÃ¬nh\n",
        "save_models()"
      ],
      "metadata": {
        "id": "w6Ubug9htQ9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -r /content/saved_models /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "E6ynOqd8tTGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load models\n",
        "plate_model = YOLO(\"/kaggle/working/saved_models/plate_detection_best.pt\")\n",
        "char_model = YOLO(\"/kaggle/working/saved_models/character_recognition_yolov8s_best.pt\")\n",
        "\n",
        "class CustomLicensePlateRecognizer:\n",
        "    def __init__(self, plate_model, char_model):\n",
        "        self.plate_model = plate_model\n",
        "        self.char_model = char_model\n",
        "\n",
        "    def recognize_from_path(self, image_path):\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            print(\"âŒ KhÃ´ng thá»ƒ Ä‘á»c áº£nh.\")\n",
        "            return None\n",
        "        return self.recognize_from_array(image)\n",
        "\n",
        "    def recognize_from_array(self, image):\n",
        "        results = []\n",
        "        plate_results = self.plate_model(image)\n",
        "        for result in plate_results:\n",
        "            if result.boxes is not None:\n",
        "                for box in result.boxes:\n",
        "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "                    plate_img = image[y1:y2, x1:x2]\n",
        "                    char_results = self.char_model(plate_img)\n",
        "                    char_detections = []\n",
        "                    for char_result in char_results:\n",
        "                        if char_result.boxes is not None:\n",
        "                            for char_box in char_result.boxes:\n",
        "                                x_char = float(char_box.xyxy[0][0])\n",
        "                                class_id = int(char_box.cls[0])\n",
        "                                conf = float(char_box.conf[0])\n",
        "                                char = char_result.names[class_id]\n",
        "                                char_detections.append((x_char, char, conf))\n",
        "                    char_detections.sort(key=lambda x: x[0])\n",
        "                    text = ''.join([c for _, c, _ in char_detections])\n",
        "                    avg_conf = sum([conf for _, _, conf in char_detections]) / len(char_detections) if char_detections else 0\n",
        "                    results.append({'text': text, 'confidence': avg_conf, 'bbox': (x1, y1, x2, y2)})\n",
        "        return results\n",
        "\n",
        "    def visualize_results(self, image_path, results):\n",
        "        image = cv2.imread(image_path)\n",
        "        for result in results:\n",
        "            x1, y1, x2, y2 = result['bbox']\n",
        "            text = result['text']\n",
        "            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "            cv2.putText(image, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "        plt.axis('off')\n",
        "        plt.title(\"Káº¿t quáº£ nháº­n dáº¡ng biá»ƒn sá»‘\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "TIwb_6kVy1uJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Khá»Ÿi táº¡o recognizer\n",
        "recognizer = CustomLicensePlateRecognizer(plate_model, char_model)\n",
        "\n",
        "# Test áº£nh\n",
        "image_path = \"/kaggle/input/test12/test.jpg\"\n",
        "print(f\"ğŸ–¼ï¸ Äang test vá»›i áº£nh: {image_path}\")\n",
        "results = recognizer.recognize_from_path(image_path)\n",
        "\n",
        "if results:\n",
        "    for i, res in enumerate(results):\n",
        "        print(f\"\\nğŸ“‹ Biá»ƒn sá»‘ {i+1}:\")\n",
        "        print(f\"ğŸ“ Text: {res['text']}\")\n",
        "        print(f\"ğŸ¯ Confidence: {res['confidence']:.2f}\")\n",
        "    recognizer.visualize_results(image_path, results)\n",
        "else:\n",
        "    print(\"âŒ KhÃ´ng nháº­n dáº¡ng Ä‘Æ°á»£c biá»ƒn sá»‘ nÃ o.\")"
      ],
      "metadata": {
        "id": "o8dGz3edy4_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "class VideoLicensePlateRecognizer:\n",
        "    def __init__(self, plate_model_path, char_model_path, output_dir=\"./output\"):\n",
        "        \"\"\"\n",
        "        Khá»Ÿi táº¡o recognizer cho video\n",
        "\n",
        "        Args:\n",
        "            plate_model_path: ÄÆ°á»ng dáº«n Ä‘áº¿n mÃ´ hÃ¬nh phÃ¡t hiá»‡n biá»ƒn sá»‘\n",
        "            char_model_path: ÄÆ°á»ng dáº«n Ä‘áº¿n mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»±\n",
        "            output_dir: ThÆ° má»¥c lÆ°u káº¿t quáº£\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.plate_model = YOLO(plate_model_path)\n",
        "            self.char_model = YOLO(char_model_path)\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"KhÃ´ng thá»ƒ táº£i model: {e}\")\n",
        "\n",
        "        self.output_dir = output_dir\n",
        "        self.detected_plates = []  # LÆ°u trá»¯ cÃ¡c biá»ƒn sá»‘ Ä‘Ã£ phÃ¡t hiá»‡n\n",
        "\n",
        "        # Táº¡o thÆ° má»¥c output\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Kiá»ƒm tra mÃ´i trÆ°á»ng GUI\n",
        "        self.has_gui = self._check_gui_support()\n",
        "\n",
        "    def _check_gui_support(self):\n",
        "        \"\"\"Kiá»ƒm tra xem mÃ´i trÆ°á»ng cÃ³ há»— trá»£ GUI khÃ´ng\"\"\"\n",
        "        try:\n",
        "            # Thá»­ táº¡o má»™t window test\n",
        "            test_img = np.zeros((100, 100, 3), dtype=np.uint8)\n",
        "            cv2.imshow('test', test_img)\n",
        "            cv2.waitKey(1)\n",
        "            cv2.destroyWindow('test')\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def recognize_plate_in_frame(self, frame):\n",
        "        \"\"\"\n",
        "        Nháº­n dáº¡ng biá»ƒn sá»‘ trong má»™t frame\n",
        "\n",
        "        Args:\n",
        "            frame: Frame áº£nh tá»« video\n",
        "\n",
        "        Returns:\n",
        "            List cÃ¡c biá»ƒn sá»‘ Ä‘Æ°á»£c phÃ¡t hiá»‡n\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        try:\n",
        "            # PhÃ¡t hiá»‡n biá»ƒn sá»‘ vá»›i verbose=False Ä‘á»ƒ giáº£m log\n",
        "            plate_results = self.plate_model(frame, conf=0.5, verbose=False)\n",
        "\n",
        "            for result in plate_results:\n",
        "                if result.boxes is not None:\n",
        "                    for box in result.boxes:\n",
        "                        # Láº¥y tá»a Ä‘á»™ biá»ƒn sá»‘\n",
        "                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
        "                        plate_conf = float(box.conf[0])\n",
        "\n",
        "                        # Kiá»ƒm tra tá»a Ä‘á»™ há»£p lá»‡\n",
        "                        if x2 <= x1 or y2 <= y1:\n",
        "                            continue\n",
        "\n",
        "                        # Cáº¯t vÃ¹ng biá»ƒn sá»‘ vá»›i kiá»ƒm tra bounds\n",
        "                        h, w = frame.shape[:2]\n",
        "                        x1, y1 = max(0, x1), max(0, y1)\n",
        "                        x2, y2 = min(w, x2), min(h, y2)\n",
        "\n",
        "                        plate_img = frame[y1:y2, x1:x2]\n",
        "\n",
        "                        if plate_img.size == 0:\n",
        "                            continue\n",
        "\n",
        "                        # Nháº­n dáº¡ng kÃ½ tá»± trong biá»ƒn sá»‘ vá»›i verbose=False\n",
        "                        char_results = self.char_model(plate_img, conf=0.3, verbose=False)\n",
        "                        char_detections = []\n",
        "\n",
        "                        for char_result in char_results:\n",
        "                            if char_result.boxes is not None:\n",
        "                                for char_box in char_result.boxes:\n",
        "                                    x_char = float(char_box.xyxy[0][0])\n",
        "                                    class_id = int(char_box.cls[0])\n",
        "                                    conf = float(char_box.conf[0])\n",
        "                                    char = char_result.names[class_id]\n",
        "                                    char_detections.append((x_char, char, conf))\n",
        "\n",
        "                        # Sáº¯p xáº¿p kÃ½ tá»± theo thá»© tá»± tá»« trÃ¡i sang pháº£i\n",
        "                        char_detections.sort(key=lambda x: x[0])\n",
        "\n",
        "                        # GhÃ©p thÃ nh chuá»—i biá»ƒn sá»‘\n",
        "                        text = ''.join([c for _, c, _ in char_detections])\n",
        "                        avg_conf = sum([conf for _, _, conf in char_detections]) / len(char_detections) if char_detections else 0\n",
        "\n",
        "                        # Chá»‰ láº¥y biá»ƒn sá»‘ cÃ³ Ä‘á»™ tin cáº­y cao vÃ  cÃ³ Ã­t nháº¥t 6 kÃ½ tá»±\n",
        "                        if avg_conf > 0.5 and len(text) >= 6:\n",
        "                            results.append({\n",
        "                                'text': text,\n",
        "                                'confidence': avg_conf,\n",
        "                                'plate_conf': plate_conf,\n",
        "                                'bbox': (x1, y1, x2, y2),\n",
        "                                'plate_img': plate_img\n",
        "                            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Lá»—i khi nháº­n dáº¡ng frame: {e}\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    def draw_results_on_frame(self, frame, results, frame_number=0):\n",
        "        \"\"\"\n",
        "        Váº½ káº¿t quáº£ lÃªn frame\n",
        "\n",
        "        Args:\n",
        "            frame: Frame gá»‘c\n",
        "            results: Káº¿t quáº£ nháº­n dáº¡ng\n",
        "            frame_number: Sá»‘ thá»© tá»± frame\n",
        "\n",
        "        Returns:\n",
        "            Frame Ä‘Ã£ Ä‘Æ°á»£c váº½ káº¿t quáº£\n",
        "        \"\"\"\n",
        "        annotated_frame = frame.copy()\n",
        "\n",
        "        for result in results:\n",
        "            x1, y1, x2, y2 = result['bbox']\n",
        "            text = result['text']\n",
        "            confidence = result['confidence']\n",
        "\n",
        "            # Váº½ khung biá»ƒn sá»‘\n",
        "            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "\n",
        "            # Táº¡o background cho text\n",
        "            label = f\"{text} ({confidence:.2f})\"\n",
        "            (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)\n",
        "\n",
        "            # Äáº£m báº£o text khÃ´ng vÆ°á»£t ra ngoÃ i frame\n",
        "            text_y = max(y1 - 5, text_height + 5)\n",
        "            cv2.rectangle(annotated_frame, (x1, text_y - text_height - 5),\n",
        "                         (x1 + text_width, text_y + 5), (0, 255, 0), -1)\n",
        "\n",
        "            # Váº½ text\n",
        "            cv2.putText(annotated_frame, label, (x1, text_y),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)\n",
        "\n",
        "        # ThÃªm timestamp\n",
        "        timestamp = f\"Frame: {frame_number}\"\n",
        "        cv2.putText(annotated_frame, timestamp, (10, 30),\n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "        return annotated_frame\n",
        "\n",
        "    def process_video(self, input_video_path, output_video_path=None, save_plates=True,\n",
        "                     skip_frames=1, max_frames=None, show_progress=True):\n",
        "        \"\"\"\n",
        "        Xá»­ lÃ½ video Ä‘á»ƒ nháº­n dáº¡ng biá»ƒn sá»‘\n",
        "\n",
        "        Args:\n",
        "            input_video_path: ÄÆ°á»ng dáº«n video Ä‘áº§u vÃ o\n",
        "            output_video_path: ÄÆ°á»ng dáº«n video Ä‘áº§u ra (náº¿u None sáº½ tá»± táº¡o)\n",
        "            save_plates: CÃ³ lÆ°u áº£nh biá»ƒn sá»‘ hay khÃ´ng\n",
        "            skip_frames: Sá»‘ frame bá» qua Ä‘á»ƒ tÄƒng tá»‘c Ä‘á»™ xá»­ lÃ½\n",
        "            max_frames: Sá»‘ frame tá»‘i Ä‘a Ä‘á»ƒ xá»­ lÃ½ (None = xá»­ lÃ½ háº¿t)\n",
        "            show_progress: Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh\n",
        "\n",
        "        Returns:\n",
        "            Dictionary chá»©a thá»‘ng kÃª káº¿t quáº£\n",
        "        \"\"\"\n",
        "        # Má»Ÿ video Ä‘áº§u vÃ o\n",
        "        cap = cv2.VideoCapture(input_video_path)\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"KhÃ´ng thá»ƒ má»Ÿ video: {input_video_path}\")\n",
        "\n",
        "        # Láº¥y thÃ´ng tin video\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "        if show_progress:\n",
        "            print(f\"ğŸ“¹ ThÃ´ng tin video:\")\n",
        "            print(f\"   - FPS: {fps}\")\n",
        "            print(f\"   - KÃ­ch thÆ°á»›c: {width}x{height}\")\n",
        "            print(f\"   - Tá»•ng frames: {total_frames}\")\n",
        "            print(f\"   - GUI Support: {'CÃ³' if self.has_gui else 'KhÃ´ng'}\")\n",
        "\n",
        "        # Táº¡o tÃªn file output náº¿u khÃ´ng Ä‘Æ°á»£c cung cáº¥p\n",
        "        if output_video_path is None:\n",
        "            base_name = os.path.splitext(os.path.basename(input_video_path))[0]\n",
        "            output_video_path = os.path.join(self.output_dir, f\"{base_name}_processed.mp4\")\n",
        "\n",
        "        # Khá»Ÿi táº¡o video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "        if not out.isOpened():\n",
        "            raise ValueError(f\"KhÃ´ng thá»ƒ táº¡o video output: {output_video_path}\")\n",
        "\n",
        "        # Khá»Ÿi táº¡o biáº¿n thá»‘ng kÃª\n",
        "        frame_count = 0\n",
        "        processed_frames = 0\n",
        "        unique_plates = set()\n",
        "        all_detections = []\n",
        "\n",
        "        # Táº¡o thÆ° má»¥c lÆ°u áº£nh biá»ƒn sá»‘\n",
        "        if save_plates:\n",
        "            plates_dir = os.path.join(self.output_dir, \"detected_plates\")\n",
        "            os.makedirs(plates_dir, exist_ok=True)\n",
        "\n",
        "        if show_progress:\n",
        "            print(f\"ğŸ”„ Báº¯t Ä‘áº§u xá»­ lÃ½ video...\")\n",
        "\n",
        "        try:\n",
        "            while True:\n",
        "                ret, frame = cap.read()\n",
        "                if not ret:\n",
        "                    break\n",
        "\n",
        "                frame_count += 1\n",
        "\n",
        "                # Bá» qua frame náº¿u cáº§n\n",
        "                if frame_count % (skip_frames + 1) != 0:\n",
        "                    out.write(frame)\n",
        "                    continue\n",
        "\n",
        "                # Giá»›i háº¡n sá»‘ frame xá»­ lÃ½\n",
        "                if max_frames and processed_frames >= max_frames:\n",
        "                    out.write(frame)\n",
        "                    continue\n",
        "\n",
        "                # Nháº­n dáº¡ng biá»ƒn sá»‘\n",
        "                results = self.recognize_plate_in_frame(frame)\n",
        "\n",
        "                # Váº½ káº¿t quáº£ lÃªn frame\n",
        "                annotated_frame = self.draw_results_on_frame(frame, results, frame_count)\n",
        "\n",
        "                # LÆ°u káº¿t quáº£\n",
        "                for i, result in enumerate(results):\n",
        "                    plate_text = result['text']\n",
        "                    timestamp = frame_count / fps if fps > 0 else 0\n",
        "\n",
        "                    # ThÃªm vÃ o danh sÃ¡ch phÃ¡t hiá»‡n\n",
        "                    detection_info = {\n",
        "                        'frame': frame_count,\n",
        "                        'timestamp': timestamp,\n",
        "                        'plate_text': plate_text,\n",
        "                        'confidence': result['confidence'],\n",
        "                        'plate_confidence': result['plate_conf'],\n",
        "                        'bbox': result['bbox']\n",
        "                    }\n",
        "                    all_detections.append(detection_info)\n",
        "\n",
        "                    # ThÃªm vÃ o set biá»ƒn sá»‘ unique\n",
        "                    if result['confidence'] > 0.7:  # Chá»‰ láº¥y biá»ƒn sá»‘ cÃ³ Ä‘á»™ tin cáº­y cao\n",
        "                        unique_plates.add(plate_text)\n",
        "\n",
        "                    # LÆ°u áº£nh biá»ƒn sá»‘\n",
        "                    if save_plates and result['confidence'] > 0.6:\n",
        "                        try:\n",
        "                            plate_filename = f\"plate_{frame_count}_{i}_{plate_text}.jpg\"\n",
        "                            # Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t trong tÃªn file\n",
        "                            plate_filename = \"\".join(c for c in plate_filename if c.isalnum() or c in \"._-\")\n",
        "                            plate_path = os.path.join(plates_dir, plate_filename)\n",
        "                            cv2.imwrite(plate_path, result['plate_img'])\n",
        "                        except Exception as e:\n",
        "                            print(f\"âš ï¸ KhÃ´ng thá»ƒ lÆ°u áº£nh biá»ƒn sá»‘: {e}\")\n",
        "\n",
        "                # Ghi frame Ä‘Ã£ xá»­ lÃ½\n",
        "                out.write(annotated_frame)\n",
        "                processed_frames += 1\n",
        "\n",
        "                # Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh\n",
        "                if show_progress and frame_count % 100 == 0:\n",
        "                    progress = (frame_count / total_frames) * 100\n",
        "                    print(f\"   Tiáº¿n trÃ¬nh: {progress:.1f}% ({frame_count}/{total_frames})\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nâš ï¸ ÄÃ£ dá»«ng xá»­ lÃ½ theo yÃªu cáº§u ngÆ°á»i dÃ¹ng\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Lá»—i trong quÃ¡ trÃ¬nh xá»­ lÃ½: {e}\")\n",
        "\n",
        "        finally:\n",
        "            # Giáº£i phÃ³ng tÃ i nguyÃªn - FIX CHO Lá»–I GUI\n",
        "            cap.release()\n",
        "            out.release()\n",
        "\n",
        "            # Chá»‰ gá»i destroyAllWindows náº¿u cÃ³ há»— trá»£ GUI\n",
        "            if self.has_gui:\n",
        "                try:\n",
        "                    cv2.destroyAllWindows()\n",
        "                except:\n",
        "                    pass  # Bá» qua lá»—i náº¿u khÃ´ng thá»ƒ destroy windows\n",
        "\n",
        "        # LÆ°u káº¿t quáº£ ra file\n",
        "        self.save_detection_results(all_detections, unique_plates)\n",
        "\n",
        "        # Thá»‘ng kÃª káº¿t quáº£\n",
        "        stats = {\n",
        "            'total_frames': total_frames,\n",
        "            'processed_frames': processed_frames,\n",
        "            'total_detections': len(all_detections),\n",
        "            'unique_plates': len(unique_plates),\n",
        "            'output_video': output_video_path,\n",
        "            'unique_plates_list': list(unique_plates)\n",
        "        }\n",
        "\n",
        "        if show_progress:\n",
        "            self.print_summary(stats)\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def save_detection_results(self, all_detections, unique_plates):\n",
        "        \"\"\"\n",
        "        LÆ°u káº¿t quáº£ nháº­n dáº¡ng ra file\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # LÆ°u chi tiáº¿t táº¥t cáº£ cÃ¡c phÃ¡t hiá»‡n\n",
        "            detections_file = os.path.join(self.output_dir, \"all_detections.json\")\n",
        "            with open(detections_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(all_detections, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "            # LÆ°u danh sÃ¡ch biá»ƒn sá»‘ unique\n",
        "            unique_plates_file = os.path.join(self.output_dir, \"unique_plates.txt\")\n",
        "            with open(unique_plates_file, 'w', encoding='utf-8') as f:\n",
        "                for plate in sorted(unique_plates):\n",
        "                    f.write(f\"{plate}\\n\")\n",
        "\n",
        "            # LÆ°u thÃ nh CSV Ä‘á»ƒ dá»… phÃ¢n tÃ­ch\n",
        "            if all_detections:\n",
        "                df = pd.DataFrame(all_detections)\n",
        "                csv_file = os.path.join(self.output_dir, \"detections.csv\")\n",
        "                df.to_csv(csv_file, index=False, encoding='utf-8')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Lá»—i khi lÆ°u káº¿t quáº£: {e}\")\n",
        "\n",
        "    def print_summary(self, stats):\n",
        "        \"\"\"\n",
        "        In tÃ³m táº¯t káº¿t quáº£\n",
        "        \"\"\"\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"ğŸ“Š TÃ“M Táº®T Káº¾T QUáº¢ Xá»¬ LÃ VIDEO\")\n",
        "        print(f\"{'='*50}\")\n",
        "        print(f\"ğŸ¬ Tá»•ng sá»‘ frames: {stats['total_frames']}\")\n",
        "        print(f\"âš¡ Frames Ä‘Ã£ xá»­ lÃ½: {stats['processed_frames']}\")\n",
        "        print(f\"ğŸ” Tá»•ng sá»‘ láº§n phÃ¡t hiá»‡n: {stats['total_detections']}\")\n",
        "        print(f\"ğŸš— Sá»‘ biá»ƒn sá»‘ unique: {stats['unique_plates']}\")\n",
        "        print(f\"ğŸ“ Video Ä‘áº§u ra: {stats['output_video']}\")\n",
        "\n",
        "        if stats['unique_plates_list']:\n",
        "            print(f\"\\nğŸ“‹ DANH SÃCH BIá»‚N Sá» PHÃT HIá»†N:\")\n",
        "            for i, plate in enumerate(sorted(stats['unique_plates_list']), 1):\n",
        "                print(f\"   {i:2d}. {plate}\")\n",
        "\n",
        "        print(f\"\\nğŸ“‚ Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {self.output_dir}\")\n",
        "        print(f\"{'='*50}\")\n",
        "\n",
        "# HÃ m tiá»‡n Ã­ch Ä‘á»ƒ sá»­ dá»¥ng\n",
        "def process_video_with_license_plate_recognition(\n",
        "    input_video_path,\n",
        "    plate_model_path=\"/kaggle/working/saved_models/plate_detection_best.pt\",\n",
        "    char_model_path=\"/kaggle/working/saved_models/character_recognition_yolov8s_best.pt\",\n",
        "    output_dir=\"./video_output\",\n",
        "    skip_frames=2,  # Xá»­ lÃ½ má»—i 3 frames Ä‘á»ƒ tÄƒng tá»‘c\n",
        "    max_frames=None,\n",
        "    show_progress=True\n",
        "):\n",
        "    \"\"\"\n",
        "    HÃ m wrapper Ä‘á»ƒ xá»­ lÃ½ video nháº­n dáº¡ng biá»ƒn sá»‘\n",
        "\n",
        "    Args:\n",
        "        input_video_path: ÄÆ°á»ng dáº«n video Ä‘áº§u vÃ o\n",
        "        plate_model_path: ÄÆ°á»ng dáº«n mÃ´ hÃ¬nh phÃ¡t hiá»‡n biá»ƒn sá»‘\n",
        "        char_model_path: ÄÆ°á»ng dáº«n mÃ´ hÃ¬nh nháº­n dáº¡ng kÃ½ tá»±\n",
        "        output_dir: ThÆ° má»¥c lÆ°u káº¿t quáº£\n",
        "        skip_frames: Sá»‘ frame bá» qua (0 = xá»­ lÃ½ táº¥t cáº£)\n",
        "        max_frames: Sá»‘ frame tá»‘i Ä‘a xá»­ lÃ½ (None = xá»­ lÃ½ háº¿t)\n",
        "        show_progress: Hiá»ƒn thá»‹ tiáº¿n trÃ¬nh\n",
        "\n",
        "    Returns:\n",
        "        Dictionary chá»©a thá»‘ng kÃª káº¿t quáº£\n",
        "    \"\"\"\n",
        "    try:\n",
        "        recognizer = VideoLicensePlateRecognizer(\n",
        "            plate_model_path=plate_model_path,\n",
        "            char_model_path=char_model_path,\n",
        "            output_dir=output_dir\n",
        "        )\n",
        "\n",
        "        return recognizer.process_video(\n",
        "            input_video_path=input_video_path,\n",
        "            skip_frames=skip_frames,\n",
        "            max_frames=max_frames,\n",
        "            show_progress=show_progress\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Lá»—i khá»Ÿi táº¡o recognizer: {e}\")\n",
        "        return None\n",
        "\n",
        "# VÃ­ dá»¥ sá»­ dá»¥ng\n",
        "if __name__ == \"__main__\":\n",
        "    # Xá»­ lÃ½ video\n",
        "    input_video = \"/kaggle/input/test78/plate_video (1) (online-video-cutter.com).mp4\"\n",
        "\n",
        "    try:\n",
        "        stats = process_video_with_license_plate_recognition(\n",
        "            input_video_path=input_video,\n",
        "            output_dir=\"./license_plate_output\",\n",
        "            skip_frames=1,  # Xá»­ lÃ½ má»—i 2 frames\n",
        "            max_frames=1000,  # Xá»­ lÃ½ tá»‘i Ä‘a 1000 frames Ä‘á»ƒ test\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "        if stats:\n",
        "            print(\"âœ… Xá»­ lÃ½ video hoÃ n thÃ nh!\")\n",
        "        else:\n",
        "            print(\"âŒ Xá»­ lÃ½ video tháº¥t báº¡i!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Lá»—i khi xá»­ lÃ½ video: {e}\")"
      ],
      "metadata": {
        "id": "K1YI5U-Hy81X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}